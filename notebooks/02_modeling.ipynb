{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement données\n",
    "df = pd.read_csv('../src/get_around_pricing_project_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features numériques: 9\n",
      "Features catégorielles: 4\n",
      "\n",
      "Types de données:\n",
      "mileage: int64\n",
      "engine_power: int64\n",
      "private_parking_available: bool\n",
      "has_gps: bool\n",
      "has_air_conditioning: bool\n",
      "automatic_car: bool\n",
      "has_getaround_connect: bool\n",
      "has_speed_regulator: bool\n",
      "winter_tires: bool\n",
      "model_key: object\n",
      "fuel: object\n",
      "paint_color: object\n",
      "car_type: object\n"
     ]
    }
   ],
   "source": [
    "# Features numériques (incluant binaires)\n",
    "numeric_features = ['mileage', 'engine_power',\n",
    "                  'private_parking_available', 'has_gps', \n",
    "                  'has_air_conditioning', 'automatic_car',\n",
    "                  'has_getaround_connect', 'has_speed_regulator', \n",
    "                  'winter_tires']\n",
    "\n",
    "# Features catégorielles\n",
    "categorical_features = ['model_key', 'fuel', 'paint_color', 'car_type']\n",
    "\n",
    "print(\"Features numériques:\", len(numeric_features))\n",
    "print(\"Features catégorielles:\", len(categorical_features))\n",
    "\n",
    "# Vérification des types\n",
    "print(\"\\nTypes de données:\")\n",
    "for col in numeric_features:\n",
    "   print(f\"{col}: {df[col].dtype}\")\n",
    "for col in categorical_features:\n",
    "    print(f\"{col}: {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (3872, 13)\n",
      "Test set: (968, 13)\n"
     ]
    }
   ],
   "source": [
    "# Séparation features/target\n",
    "X = df.drop(['rental_price_per_day', 'Unnamed: 0'], axis=1)\n",
    "y = df['rental_price_per_day']\n",
    "\n",
    "# Train/test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train set:\", X_train.shape)\n",
    "print(\"Test set:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline():    \n",
    "    # Preprocessing numérique\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Preprocessing catégoriel\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train transformé: (3872, 54)\n",
      "X_test transformé: (968, 54)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import des dépendances manquantes\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Création du preprocessing pipeline\n",
    "preprocessor = create_pipeline()\n",
    "\n",
    "# Fit et transform sur les données d'entraînement\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Vérification des dimensions\n",
    "print(\"X_train transformé:\", X_train_processed.shape)\n",
    "print(\"X_test transformé:\", X_test_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## BASELINE\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression performances:\n",
      "RMSE: 18.41\n",
      "MAE: 12.41\n",
      "R²: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "\n",
    "# Pipeline avec Linear Regression\n",
    "lr_pipeline = Pipeline([\n",
    "   ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit\n",
    "lr_pipeline.fit(X_train_processed, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = lr_pipeline.predict(X_test_processed)\n",
    "\n",
    "# Métriques\n",
    "print(\"Linear Regression performances:\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_test, y_pred):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur modèle: {'regressor': Ridge(), 'regressor__alpha': 1.0}\n",
      "\n",
      "Meilleures performances:\n",
      "RMSE: 18.23\n",
      "MAE: 12.38\n",
      "R²: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Pipeline avec GridSearch pour Ridge et Lasso\n",
    "param_grid = {\n",
    "    'regressor': [Ridge(), Lasso()],\n",
    "    'regressor__alpha': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "grid_pipeline = GridSearchCV(\n",
    "    Pipeline([('regressor', Ridge())]),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Fit\n",
    "grid_pipeline.fit(X_train_processed, y_train)\n",
    "\n",
    "# Résultats\n",
    "print(\"Meilleur modèle:\", grid_pipeline.best_params_)\n",
    "y_pred = grid_pipeline.predict(X_test_processed)\n",
    "print(\"\\nMeilleures performances:\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_test, y_pred):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge avec alpha=1.0 améliore légèrement les performances :\n",
    "- RMSE : 18.41 → 18.23\n",
    "- MAE : 12.41 → 12.38\n",
    "- R² : 0.70 → 0.71\n",
    "\n",
    "C'est une bonne baseline avec :\n",
    "- Erreur moyenne d'environ 18$\n",
    "- 71% de variance expliquée\n",
    "- Modèle simple et interprétable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## BASELINE AVEC FONCTION\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performances:\n",
      "Best params: {'regressor': Ridge(), 'regressor__alpha': 1.0}\n",
      "RMSE: 18.23\n",
      "MAE: 12.38\n",
      "R2: 0.71\n"
     ]
    }
   ],
   "source": [
    "def create_baseline_model():\n",
    "    # Création du preprocessor\n",
    "    preprocessor = create_pipeline()\n",
    "    \n",
    "    # Pipeline avec GridSearch pour Ridge et Lasso\n",
    "    param_grid = {\n",
    "        'regressor': [Ridge(), Lasso()],\n",
    "        'regressor__alpha': [0.1, 1.0, 10.0]\n",
    "    }\n",
    "    \n",
    "    base_model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', Ridge())\n",
    "    ])\n",
    "    \n",
    "    # GridSearch\n",
    "    model = GridSearchCV(\n",
    "        base_model,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error'\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_evaluate_model(model, X, y):\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = {\n",
    "        'RMSE': root_mean_squared_error(y_test, y_pred),\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    return model, metrics\n",
    "\n",
    "# Test\n",
    "baseline_model = create_baseline_model()\n",
    "trained_baseline, baseline_metrics = train_evaluate_model(baseline_model, X, y)\n",
    "\n",
    "print(\"Baseline performances:\")\n",
    "print(\"Best params:\", baseline_model.best_params_)\n",
    "for metric, value in baseline_metrics.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## XGBOOST\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost performances:\n",
      "RMSE: 16.61\n",
      "MAE: 10.80\n",
      "R²: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "xgb_model.fit(X_train_processed, y_train)\n",
    "y_pred = xgb_model.predict(X_test_processed)\n",
    "\n",
    "# Métriques\n",
    "print(\"XGBoost performances:\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_test, y_pred):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performances XGBoost initiales:\n",
      "RMSE: 16.61\n",
      "MAE: 10.80\n",
      "R²: 0.76\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-2491.307 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-2659.432 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-2461.657 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-2497.689 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-2567.850 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-663.861 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-830.719 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-652.453 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-627.218 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-643.679 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-2438.654 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-2609.371 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-2401.839 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-2428.689 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-2508.711 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-609.897 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-767.186 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-592.462 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-577.453 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-583.881 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=-2433.370 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=-2593.873 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=-2394.990 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=-2414.694 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=-2507.294 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=-595.148 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=-739.464 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=-567.325 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=-555.044 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=-575.509 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-290.845 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-445.224 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-289.790 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-246.548 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-232.221 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-272.991 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-424.085 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-268.500 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-238.848 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-216.864 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-255.296 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-414.275 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-274.631 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-248.696 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-224.940 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-242.285 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-405.136 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-265.613 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-243.700 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-223.646 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=-247.175 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=-401.657 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=-252.670 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=-241.449 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=-220.108 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=-246.618 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=-398.961 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=-253.883 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=-246.443 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=-219.982 total time=   0.2s\n",
      "Meilleurs paramètres: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}\n",
      "\n",
      "Performances du meilleur modèle XGBoost:\n",
      "RMSE: 16.15\n",
      "MAE: 10.51\n",
      "R²: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "# Définir le modèle initial\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# Entraînement initial pour vérifier que le modèle fonctionne\n",
    "xgb_model.fit(X_train_processed, y_train)\n",
    "y_pred = xgb_model.predict(X_test_processed)\n",
    "\n",
    "# Afficher les métriques du modèle initial\n",
    "print(\"Performances XGBoost initiales:\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_test, y_pred):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "# Définir les paramètres pour GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "# Configuration de GridSearchCV\n",
    "grid_xgb = GridSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring= 'neg_mean_squared_error',\n",
    "    verbose=3  # Affiche les détails des étapes\n",
    ")\n",
    "\n",
    "# Lancer GridSearchCV\n",
    "grid_xgb.fit(X_train_processed, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramètres trouvés\n",
    "print(\"Meilleurs paramètres:\", grid_xgb.best_params_)\n",
    "\n",
    "# Faire des prédictions avec le meilleur modèle\n",
    "y_pred = grid_xgb.best_estimator_.predict(X_test_processed)\n",
    "\n",
    "# Afficher les métriques finales\n",
    "print(\"\\nPerformances du meilleur modèle XGBoost:\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_test, y_pred):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-2491.307 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-2659.432 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-2461.657 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-2497.689 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-2567.850 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-663.861 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-830.719 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-652.453 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-627.218 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-643.679 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-2438.654 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-2609.371 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-2401.839 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-2428.689 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-2508.711 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-609.897 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-767.186 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-592.462 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-577.453 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-583.881 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=-2433.370 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=-2593.873 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=-2394.990 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=-2414.694 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=-2507.294 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=-595.148 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=-739.464 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=-567.325 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=-555.044 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=-575.509 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-290.845 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-445.224 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-289.790 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-246.548 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-232.221 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-272.991 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-424.085 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-268.500 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-238.848 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-216.864 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-255.296 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-414.275 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-274.631 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-248.696 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-224.940 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-242.285 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-405.136 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-265.613 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-243.700 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-223.646 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=-247.175 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=-401.657 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=-252.670 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=-241.449 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=-220.108 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=-246.618 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=-398.961 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=-253.883 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=-246.443 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=-219.982 total time=   0.2s\n",
      "Meilleurs paramètres: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}\n",
      "\n",
      "Meilleures performances XGBoost:\n",
      "RMSE: 16.15\n",
      "MAE: 10.51\n",
      "R²: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Fit GridSearch\n",
    "grid_xgb.fit(X_train_processed, y_train)\n",
    "\n",
    "\n",
    "# Affichage meilleurs paramètres\n",
    "print(\"Meilleurs paramètres:\", grid_xgb.best_params_)\n",
    "\n",
    "# Prédictions avec meilleur modèle\n",
    "y_pred = grid_xgb.predict(X_test_processed)\n",
    "\n",
    "# Métriques finales\n",
    "print(\"\\nMeilleures performances XGBoost:\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_test, y_pred):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Grid auto\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GridSearch pour XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "# créatio un nouveau XGBRegressor\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_xgb = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## entrainement avec gridauto\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}\n",
      "\n",
      "Meilleures performances XGBoost:\n",
      "RMSE: 16.15\n",
      "MAE: 10.51\n",
      "R²: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Fit GridSearch\n",
    "grid_xgb.fit(X_train_processed, y_train)\n",
    "\n",
    "\n",
    "# Affichage meilleurs paramètres\n",
    "print(\"Meilleurs paramètres:\", grid_xgb.best_params_)\n",
    "\n",
    "# Prédictions avec meilleur modèle\n",
    "y_pred = grid_xgb.predict(X_test_processed)\n",
    "\n",
    "# Métriques finales\n",
    "print(\"\\nMeilleures performances XGBoost:\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_test, y_pred):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison finale avec Ridge :\n",
    "1. Ridge (baseline) :\n",
    "   - RMSE : 18.23\n",
    "   - MAE : 12.38\n",
    "   - R² : 0.71\n",
    "\n",
    "2. XGBoost (meilleur modèle) :\n",
    "   - RMSE : 16.15\n",
    "   - MAE : 10.51\n",
    "   - R² : 0.77\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## VERSION XGBOOST AVEC FONCTION\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_type='xgboost', best_params=None):\n",
    "    # Création du preprocessor\n",
    "    preprocessor = create_pipeline()\n",
    "    \n",
    "    # Choix du modèle\n",
    "    if model_type == 'xgboost':\n",
    "        if best_params:\n",
    "            regressor = XGBRegressor(**best_params, random_state=42)\n",
    "        else:\n",
    "            regressor = XGBRegressor(\n",
    "                learning_rate=0.1, \n",
    "                max_depth=5, \n",
    "                n_estimators=200,\n",
    "                random_state=42\n",
    "            )\n",
    "    elif model_type == 'ridge':\n",
    "        regressor = Ridge(alpha=1.0)\n",
    "    \n",
    "    # Création du pipeline complet\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_evaluate_model(model, X, y):\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = {\n",
    "        'RMSE': root_mean_squared_error(y_test, y_pred),\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost performances:\n",
      "RMSE: 16.08\n",
      "MAE: 10.45\n",
      "R2: 0.77\n",
      "\n",
      "Ridge performances:\n",
      "RMSE: 18.23\n",
      "MAE: 12.38\n",
      "R2: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\dsgat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test avec XGBoost\n",
    "xgb_model = create_model('xgboost')\n",
    "trained_xgb, xgb_metrics = train_evaluate_model(xgb_model, X, y)\n",
    "\n",
    "print(\"XGBoost performances:\")\n",
    "for metric, value in xgb_metrics.items():\n",
    "   print(f\"{metric}: {value:.2f}\")\n",
    "\n",
    "# Test avec Ridge\n",
    "ridge_model = create_model('ridge')\n",
    "trained_ridge, ridge_metrics = train_evaluate_model(ridge_model, X, y)\n",
    "\n",
    "print(\"\\nRidge performances:\")\n",
    "for metric, value in ridge_metrics.items():\n",
    "   print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "## Comparaison des Modèles\n",
    "\n",
    "1. Baseline (Ridge) :\n",
    "   - RMSE : 18.23$\n",
    "   - MAE : 12.38$\n",
    "   - R² : 0.71\n",
    "   - Avantages : Simple, interprétable\n",
    "   - Limitations : Performances limitées\n",
    "\n",
    "2. XGBoost (optimisé) :\n",
    "   - RMSE : 16.08$\n",
    "   - MAE : 10.45$\n",
    "   - R² : 0.77\n",
    "   - Avantages : Meilleures performances\n",
    "   - Limitations : Plus complexe\n",
    "\n",
    "## Recommandation\n",
    "→ XGBoost comme modèle final car :\n",
    "- Meilleures performances globales\n",
    "- Bonne gestion des relations non-linéaires\n",
    "- Compromis acceptable complexité/performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
